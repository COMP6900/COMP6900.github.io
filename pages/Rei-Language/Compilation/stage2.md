---
layout: page
title: Stage 2
parent: Compilation
grand_parent: Rei
nav_order: 1
---

# Syntax Analysis

This is the second major part of a compiler 'frontend' that actually tries to build meaning from tokens and attributes
Based on ordering, tree structuring, etc

## Overview

The lexical analyser sends tokens to the parser, which forms a parse tree. When the entire sequence has been processed, so should the parse tree. Assume the output of a parser is always a parse tree like structure
- the parse tree is useful since we can use it to form a more generalised, lower level IR of the source code. This IR can expand on stuff to make everything explicit as possible and be generalised enough to do analysis on, i.e. optimisation steps
- each step of the frontend usually has access to the global symbol table formed in the lexical analyser

## Grammars

Type 1 -> Universal \
Type 2 -> Top-Down \
Type 3 -> Bottom-Up

In most cases, a bottom-up grammar is better since the parsers for them are more efficient

For universal parsing, we can use CYK or Earley's algorithm. These are quite inefficient, so much so that they arent really practical in real life situations

If we want a really efficient parser (TD or BU), they usually only work for certain classes of grammars. Namely LL and LR
- these grammars are expressive enough to describe most of the syntax/nesting in most modern languages. So they dont seem like a bad choice
- LL can be implemented by hand
- LR are ormally generated using automated tools

### Representative Grammars

Constructs that begin with `while`, `if`, and other "structured" keywords are usually easier to parse. But expressions that involve identifiers and operators are more of a problem
- operators should have a precedence, like `()` before everything else, `*` and `/` before `+` and `-`, etc.

We can specify a list of 'rules' for expressions:

```
E -> E + T | T
T -> T * F | F
F -> (E) | id
```

- these rules describe the associativity and precedence of terms. `(expression)` expressions are prioritised. `*` expressions are next in line. And `+` are the least priority
- note how the priority is built from `F` and `T` then `E`. If we look at it from top-bottom, it is recursive. This means the grammar is an LR grammar. LR grammars can be parsed bottom-up

For a top-down grammar, we dont use recursion. Instead we specify extra rules:
```
E -> T E'
E' -> + T E' | epsilon
T -> F T'
T' -> *F T' | epsilon
F -> (E) | id 
```

- note how the grammars are all 'circular'. `F` relies on `E` and vice-versa

## Errors in Syntax

Compilers cant expect the input to be always correct. Humans make mistakes. Many mistakes. The compiler should even expect some common mistakes (e.g. rust) and suggest ways to correct them. But at least they should be able to spot a syntax error and throw some kind of meaningful error message about the problem

- its a good idea to plan how to tackle syntax errors. Prob better if you know exactly how your language looks, edge case testing, and common errors

### Types of Errors

Lexical -> misspellings of identifiers, keywords, operators

Syntactic -> misplaced semicolons, extra/missing braces and keywords

Semantic -> mismatch between operators and operands. Prob a bit harder to analyse off the bat. If you are returning an `Int` but the return type is actually `none`, then you have a syntax error
- one way is to not specify a return type sometimes

Logical -> incorrect reasoning, e.g. using the `=` operator when they actually wanted `==`. The end program may compile OK but the logic might not work as expected. These errors seem hardest to detect as they arent much to do with program validity but intention accuracy. Tests and etc should help and also a parser that checks for common things like this and raises a warning

Syntactic errors are usually easily detectable with usual parsing methods. LL and LR methods detect errors as soon as possible, if the stream of tokens do not match the grammar, then something is wrong
- usually it makes sense to just panic, print out the line and surrounding context where an error was detected, and quit

Goals of an error handler:
- report presence of errors clearly and accurately
- recover from each error quickly enough to detect subsequent errors
- minimum overhead when processing correct programs

## Context Free Grammars

The formal definition of a CFG:
- a grammar that contains terminals, nonterminals, start symbols, productions
- terminals = symbols from which strings are formed
- non-terminals = syntactic variables that represent sets of strings. A statement or expression is a nonterminal. Imposes a hierarchical structure on the language -> parse tree
- start symbol = a way to distinguish a certain nonterminal. The set of strings the nonterminal represents is the langauge generated by the grammar (lexeme). "Productions" for start symbols should be listed first
- productions = a way to specify the manner in which the terminals and nonterminals can be combined to form strings

A production consists of:
- a non terminal "head" or "left" of the production. This defines some of the strings represented by the head
- the symbol `->`
- a "body" or "right" of the production. Consists of zero or more terminals and non terminals. Describes one way in which strings of the nonterminal at the head can be constructed



